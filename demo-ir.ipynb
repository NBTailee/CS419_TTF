{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1095715,"sourceType":"datasetVersion","datasetId":612351},{"sourceId":14308446,"sourceType":"datasetVersion","datasetId":9134216},{"sourceId":14332427,"sourceType":"datasetVersion","datasetId":9150392},{"sourceId":701991,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":532680,"modelId":546428},{"sourceId":701993,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":532682,"modelId":546430},{"sourceId":702117,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":532786,"modelId":546527}],"dockerImageVersionId":30673,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -U sentence-transformers==2.2.2 transformers==4.30.2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-30T07:23:22.435172Z","iopub.execute_input":"2025-12-30T07:23:22.435590Z","iopub.status.idle":"2025-12-30T07:23:42.857354Z","shell.execute_reply.started":"2025-12-30T07:23:22.435558Z","shell.execute_reply":"2025-12-30T07:23:42.856543Z"}},"outputs":[{"name":"stdout","text":"Collecting sentence-transformers==2.2.2\n  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting transformers==4.30.2\n  Downloading transformers-4.30.2-py3-none-any.whl.metadata (113 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.6/113.6 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (4.66.1)\nRequirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (2.1.2)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (0.16.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (1.26.4)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (1.11.4)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (3.2.4)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (0.2.0)\nRequirement already satisfied: huggingface-hub>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (0.21.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.30.2) (3.13.1)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.30.2) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.30.2) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.30.2) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.30.2) (2.31.0)\nCollecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.30.2)\n  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.30.2) (0.4.2)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2024.3.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers==4.30.2) (3.1.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (3.1.2)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from nltk->sentence-transformers==2.2.2) (1.16.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.30.2) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.30.2) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.30.2) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.30.2) (2024.2.2)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers==2.2.2) (1.3.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers==2.2.2) (3.2.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->sentence-transformers==2.2.2) (9.5.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->sentence-transformers==2.2.2) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.6.0->sentence-transformers==2.2.2) (1.3.0)\nDownloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m81.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m120.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: sentence-transformers\n  Building wheel for sentence-transformers (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125923 sha256=0251712e20164b4723e7290ec72fabf29764c6a0051204caffe9ed88e351ed06\n  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\nSuccessfully built sentence-transformers\nInstalling collected packages: tokenizers, transformers, sentence-transformers\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.15.2\n    Uninstalling tokenizers-0.15.2:\n      Successfully uninstalled tokenizers-0.15.2\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.38.2\n    Uninstalling transformers-4.38.2:\n      Successfully uninstalled transformers-4.38.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nkaggle-environments 1.14.3 requires transformers>=4.33.1, but you have transformers 4.30.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed sentence-transformers-2.2.2 tokenizers-0.13.3 transformers-4.30.2\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install -q gradio==3.50.2 ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-30T07:23:42.860067Z","iopub.execute_input":"2025-12-30T07:23:42.860740Z","iopub.status.idle":"2025-12-30T07:23:53.678423Z","shell.execute_reply.started":"2025-12-30T07:23:42.860705Z","shell.execute_reply":"2025-12-30T07:23:53.677515Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"!pip uninstall scikit-learn -y\n!pip install scikit-learn==1.6.1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-30T07:23:53.679719Z","iopub.execute_input":"2025-12-30T07:23:53.679987Z","iopub.status.idle":"2025-12-30T07:24:07.246037Z","shell.execute_reply.started":"2025-12-30T07:23:53.679964Z","shell.execute_reply":"2025-12-30T07:24:07.245164Z"}},"outputs":[{"name":"stdout","text":"Found existing installation: scikit-learn 1.2.2\nUninstalling scikit-learn-1.2.2:\n  Successfully uninstalled scikit-learn-1.2.2\nCollecting scikit-learn==1.6.1\n  Downloading scikit_learn-1.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\nRequirement already satisfied: numpy>=1.19.5 in /opt/conda/lib/python3.10/site-packages (from scikit-learn==1.6.1) (1.26.4)\nRequirement already satisfied: scipy>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn==1.6.1) (1.11.4)\nRequirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn==1.6.1) (1.3.2)\nRequirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn==1.6.1) (3.2.0)\nDownloading scikit_learn-1.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m103.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: scikit-learn\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nspopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed scikit-learn-1.6.1\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import gradio as gr\nimport joblib\nimport requests\nimport re\nimport html\nfrom bs4 import BeautifulSoup\nfrom sentence_transformers import SentenceTransformer\nimport numpy as np\nimport plotly.graph_objects as go\n\n\nTFIDF_PIPELINE_PATH = \"/kaggle/input/knn-tf-idf-complete/other/default/1/complete_pipeline.joblib\"\ntfidf_bundle = joblib.load(TFIDF_PIPELINE_PATH)\ntfidf_vectorizer = tfidf_bundle[\"tfidf\"]\nchi2_selector    = tfidf_bundle[\"selector\"]\nknn_tfidf        = tfidf_bundle[\"knn\"]\n\nBERT_DIR = \"/kaggle/input/knn-bert/other/default/1\"\nknn_bert      = joblib.load(f\"{BERT_DIR}/knn_model.pkl\")\nscaler_bert   = joblib.load(f\"{BERT_DIR}/scaler.pkl\")\nselector_bert = joblib.load(f\"{BERT_DIR}/selector.pkl\")\nbert_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n\n\nLABEL_MAP = {\n    1: \"World\",\n    2: \"Sports\",\n    3: \"Business\",\n    4: \"Science / Technology\"\n}\n\n\ndef clean_text(text: str) -> str:\n    text = html.unescape(text)\n    text = re.sub(r\"<.*?>\", \"\", text)\n    text = re.sub(r\"https?://\\S+|www\\.\\S+\", \"\", text)\n    text = re.sub(r\"[^a-zA-Z\\s]\", \" \", text)\n    return re.sub(r\"\\s+\", \" \", text).strip().lower()\n\ndef build_text(title, desc):\n    return clean_text(f\"{title} {desc}\")\n\ndef extract_article(url):\n    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n    r = requests.get(url, headers=headers, timeout=10)\n    r.raise_for_status()\n    soup = BeautifulSoup(r.text, \"html.parser\")\n    title = soup.title.string.strip() if soup.title else \"\"\n    meta = soup.find(\"meta\", attrs={\"name\": \"description\"})\n    desc = meta[\"content\"].strip() if meta else \"\"\n    return title, desc\n\n\ndef toggle_inputs(mode):\n    if mode == \"URL\":\n        return gr.update(visible=True), gr.update(visible=False), gr.update(visible=False)\n    else:\n        return gr.update(visible=False), gr.update(visible=True), gr.update(visible=True)\n\n\ndef get_top_tfidf_words(text, tfidf_vectorizer, chi2_selector, top_n=10):\n    X = tfidf_vectorizer.transform([text])\n    X_sel = chi2_selector.transform(X)\n    feature_names = tfidf_vectorizer.get_feature_names_out()\n    selected_mask = chi2_selector.get_support()\n    selected_features = feature_names[selected_mask]\n\n    vector = X_sel.toarray().flatten()\n    top_indices = vector.argsort()[::-1][:top_n]\n    top_words = [(selected_features[i], vector[i]) for i in top_indices if vector[i] > 0]\n\n    return top_words\n\ndef tfidf_word_importance_plot(top_words):\n    if not top_words:\n        return go.Figure()\n    words, scores = zip(*top_words)\n    fig = go.Figure(go.Bar(x=words, y=scores, text=[f\"{v:.2f}\" for v in scores], textposition=\"auto\"))\n    fig.update_layout(title=\"Top contributing words (TF-IDF)\", margin=dict(t=50,b=10,l=10,r=10))\n    return fig\n\ndef classify(input_mode, url, title, desc, method):\n    try:\n        if input_mode == \"URL\":\n            if not url.strip():\n                return \"Please enter a URL\", \"\", \"\", \"\", None\n            title, desc = extract_article(url)\n        else:\n            if not title.strip() or not desc.strip():\n                return \"Please enter Title and Description\", \"\", \"\", \"\", None\n\n        text = build_text(title, desc)\n\n        if method == \"TF-IDF + KNN\":\n            X = tfidf_vectorizer.transform([text])\n            X = chi2_selector.transform(X)\n            pred = knn_tfidf.predict(X)[0]\n            top_words = get_top_tfidf_words(text, tfidf_vectorizer, chi2_selector, top_n=10)\n            top_words_str = \", \".join([f\"{w}:{v:.2f}\" for w, v in top_words])\n            fig = tfidf_word_importance_plot(top_words)\n        else:\n            emb = bert_model.encode([text])\n            emb = scaler_bert.transform(emb)\n            emb = selector_bert.transform(emb)\n            pred = knn_bert.predict(emb)[0]\n            top_words_str = \"\"\n            fig = go.Figure()  \n\n        return LABEL_MAP[pred], title, desc, top_words_str, fig\n\n    except Exception as e:\n        return f\"Error: {str(e)}\", \"\", \"\", \"\", go.Figure()\n\n\ndef toggle_tfidf_outputs(method):\n    if method == \"TF-IDF + KNN\":\n        return gr.update(visible=True), gr.update(visible=True)\n    else:\n        return gr.update(visible=False), gr.update(visible=False)\n\n# -----------------------------\n# Gradio UI\n# -----------------------------\nwith gr.Blocks(title=\"AG News Classification Demo\") as demo:\n    gr.Markdown(\"## AG News Classification Demo\")\n    gr.Markdown(\"Predict using **TF-IDF + KNN** or **BERT + KNN**. Visualize top contributing words for TF-IDF.\")\n\n    with gr.Row():\n        with gr.Column(scale=1):\n            input_mode = gr.Radio([\"URL\", \"Manual\"], value=\"URL\", label=\"Input Mode\")\n            url = gr.Textbox(label=\"Article URL\", visible=True)\n            title = gr.Textbox(label=\"Title\", visible=False)\n            desc  = gr.Textbox(label=\"Description\", lines=5, visible=False)\n            method = gr.Radio([\"TF-IDF + KNN\", \"BERT + KNN\"], value=\"TF-IDF + KNN\", label=\"Feature Extraction Method\")\n            btn = gr.Button(\"Classify\")\n\n        with gr.Column(scale=1):\n            out_label = gr.Textbox(label=\"Predicted Category\")\n            out_title = gr.Textbox(label=\"Title\")\n            out_desc  = gr.Textbox(label=\"Description\", lines=5)\n            out_words = gr.Textbox(label=\"Top contributing words (TF-IDF)\")\n            out_plot = gr.Plot(label=\"Word Importance Visualization\")\n\n    input_mode.change(toggle_inputs, input_mode, [url, title, desc])\n    method.change(toggle_tfidf_outputs, method, [out_words, out_plot])\n    btn.click(classify, [input_mode, url, title, desc, method],\n              [out_label, out_title, out_desc, out_words, out_plot])\n\ndemo.launch()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-30T07:24:07.247883Z","iopub.execute_input":"2025-12-30T07:24:07.248155Z","iopub.status.idle":"2025-12-30T07:24:40.974102Z","shell.execute_reply.started":"2025-12-30T07:24:07.248131Z","shell.execute_reply":"2025-12-30T07:24:40.973403Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":".gitattributes: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8b4bbc07c56c45a6b9edfa9419c3fc18"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"34cfb08118d74daa8039cbd62d6a2cd6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"595978878b2e4386b2247e10998f5957"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e7f6fa2a68234d9a8f46393d924d6844"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"91c8e63eecc34ddcb81c0e0a8716b162"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e6bb0cb780e74174a6dc0288b0ff7a13"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"604a46dc6f3242ed8b518a8c2d7eb671"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.onnx:   0%|          | 0.00/90.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8935fabc3b6047d9a9c73c4037aecb3e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model_O1.onnx:   0%|          | 0.00/90.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d14aefc97534a5cab63c1144b465260"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model_O2.onnx:   0%|          | 0.00/90.3M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"10f8e80569164bbb8de0436a35f8d01b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model_O3.onnx:   0%|          | 0.00/90.3M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a2686455dbed499487d1f4310459994c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model_O4.onnx:   0%|          | 0.00/45.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b9579e6444d4858997bb93116238b2a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model_qint8_arm64.onnx:   0%|          | 0.00/23.0M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"190c5437a8da405f897ead868def3114"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model_qint8_avx512.onnx:   0%|          | 0.00/23.0M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b9d605f83d204a529d4f0a15a93bf82c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model_qint8_avx512_vnni.onnx:   0%|          | 0.00/23.0M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f5c662d46bb94b89853fe7a3f5ad96cf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model_quint8_avx2.onnx:   0%|          | 0.00/23.0M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da97d80a3c5e430793e930f42c319bcb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"openvino_model.bin:   0%|          | 0.00/90.3M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9176bc1e7a5f46cdb19826e062f7c3bc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"openvino_model.xml: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d2f07c1f0f049a1b4b24d4432000a89"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"openvino_model_qint8_quantized.bin:   0%|          | 0.00/22.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"789716a5d4d64bb99bccc5897f7ac343"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"openvino_model_qint8_quantized.xml: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8cd5bc8c6a0645ca934c4c79dd303c69"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aeb80cfde5214beebd7a06ae178581d7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"27d9d422db5b468e844004d52490393f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d9324e890bb48338b6dd0ef55d04b38"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e309ce3f39da43ca9e3ff7ec8444efa3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7263c02f4a65472ea7c7c676edab0b65"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train_script.py: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"329ce296fe4d4ac1a92cd6fe9787a733"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a763f9c68efd439fb719e8e64bb302b3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"40b7cc70d4d0410294707866971bf8a6"}},"metadata":{}},{"name":"stdout","text":"Running on local URL:  http://127.0.0.1:7860\nIMPORTANT: You are using gradio version 3.50.2, however version 4.44.1 is available, please upgrade.\n--------\nKaggle notebooks require sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n\nRunning on public URL: https://aa2d34973eb6b90134.gradio.live\n\nThis share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<div><iframe src=\"https://aa2d34973eb6b90134.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"},"metadata":{}},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":""},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}